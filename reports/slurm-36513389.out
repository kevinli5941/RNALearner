/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DEVICES:  [<torch.cuda.device object at 0x14e0fc452670>, <torch.cuda.device object at 0x14e0fc452640>, <torch.cuda.device object at 0x14e0fc4524c0>, <torch.cuda.device object at 0x14e0fc4526a0>]
DEVICES:  [<torch.cuda.device object at 0x149d4353d5e0>, <torch.cuda.device object at 0x149d4353d670>, <torch.cuda.device object at 0x149d4353d4f0>, <torch.cuda.device object at 0x149d4353d6d0>]
DEVICES:  [<torch.cuda.device object at 0x14ed358fa550>, <torch.cuda.device object at 0x14ed358fa5e0>, <torch.cuda.device object at 0x14ed358fa460>, <torch.cuda.device object at 0x14ed358fa640>]DEVICES: 
 [<torch.cuda.device object at 0x152d994a1520>, <torch.cuda.device object at 0x152d994a15b0>, <torch.cuda.device object at 0x152d994a1430>, <torch.cuda.device object at 0x152d994a1610>]
DEBUG:  /panfs/ccds02/nobackup/people/kli3/RNALearner
DEBUG:  /panfs/ccds02/nobackup/people/kli3/RNALearner
/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  q, r = torch.qr(unstructured_block.cpu(), some = True)
/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  q, r = torch.qr(unstructured_block.cpu(), some = True)
DEBUG:  /panfs/ccds02/nobackup/people/kli3/RNALearner
/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  q, r = torch.qr(unstructured_block.cpu(), some = True)
DEBUG:  /panfs/ccds02/nobackup/people/kli3/RNALearner
/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  q, r = torch.qr(unstructured_block.cpu(), some = True)
Traceback (most recent call last):
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/pretrain.py", line 209, in <module>
    logits = model(data)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 630, in forward
    x = self.performer(x, pos_emb = layer_pos_emb, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 544, in forward
    return self.net(x, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/reversible.py", line 144, in forward
    x = x + f(x, **f_args)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 298, in forward
    return self.fn(self.norm(x), **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 395, in forward
    out = self.fast_attention(q, k, v)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 249, in forward
    q = create_kernel(q, is_query = True)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 80, in softmax_kernel
    data_dash = torch.einsum('...id,...jd->...ij', (data_normalizer * data), projection)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/functional.py", line 378, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.74 GiB total capacity; 27.41 GiB already allocated; 11.38 MiB free; 27.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/pretrain.py", line 209, in <module>
Traceback (most recent call last):
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/pretrain.py", line 209, in <module>
    logits = model(data)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    logits = model(data)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    return forward_call(*input, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 630, in forward
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 630, in forward
    x = self.performer(x, pos_emb = layer_pos_emb, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    x = self.performer(x, pos_emb = layer_pos_emb, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 544, in forward
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 544, in forward
    return self.net(x, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return self.net(x, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/reversible.py", line 144, in forward
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/reversible.py", line 144, in forward
    x = x + f(x, **f_args)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    x = x + f(x, **f_args)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 298, in forward
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 298, in forward
    return self.fn(self.norm(x), **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return self.fn(self.norm(x), **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 395, in forward
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 395, in forward
    out = self.fast_attention(q, k, v)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    out = self.fast_attention(q, k, v)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 249, in forward
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 249, in forward
    q = create_kernel(q, is_query = True)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 89, in softmax_kernel
    q = create_kernel(q, is_query = True)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 89, in softmax_kernel
    torch.exp(data_dash - diag_data -
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB (GPU 3; 31.74 GiB total capacity; 29.17 GiB already allocated; 1.00 GiB free; 29.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    torch.exp(data_dash - diag_data -
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB (GPU 2; 31.74 GiB total capacity; 29.17 GiB already allocated; 1.03 GiB free; 29.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/pretrain.py", line 209, in <module>
    logits = model(data)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 630, in forward
    x = self.performer(x, pos_emb = layer_pos_emb, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 544, in forward
    return self.net(x, output_attentions = output_attentions, **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/reversible.py", line 144, in forward
    x = x + f(x, **f_args)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 298, in forward
    return self.fn(self.norm(x), **kwargs)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 395, in forward
    out = self.fast_attention(q, k, v)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 249, in forward
    q = create_kernel(q, is_query = True)
  File "/panfs/ccds02/nobackup/people/kli3/RNALearner/performer_pytorch/performer_pytorch.py", line 89, in softmax_kernel
    torch.exp(data_dash - diag_data -
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB (GPU 1; 31.74 GiB total capacity; 29.17 GiB already allocated; 1.03 GiB free; 29.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 4094488) of binary: /home/kli3/.conda/envs/scbert/bin/python3
Traceback (most recent call last):
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/kli3/.conda/envs/scbert/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-03-08_05:57:22
  host      : gpu016.atstor.adapt.nccs.nasa.gov
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 4094489)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-03-08_05:57:22
  host      : gpu016.atstor.adapt.nccs.nasa.gov
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 4094490)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-03-08_05:57:22
  host      : gpu016.atstor.adapt.nccs.nasa.gov
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 4094491)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-08_05:57:22
  host      : gpu016.atstor.adapt.nccs.nasa.gov
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4094488)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
JobID        JobIDRaw        JobName  Partition  MaxVMSize  MaxVMSizeNode  MaxVMSizeTask  AveVMSize     MaxRSS MaxRSSNode MaxRSSTask     AveRSS MaxPages MaxPagesNode   MaxPagesTask   AvePages     MinCPU MinCPUNode MinCPUTask     AveCPU   NTasks  AllocCPUS    Elapsed      State ExitCode AveCPUFreq ReqCPUFreqMin ReqCPUFreqMax ReqCPUFreqGov     ReqMem ConsumedEnergy  MaxDiskRead MaxDiskReadNode MaxDiskReadTask    AveDiskRead MaxDiskWrite MaxDiskWriteNode MaxDiskWriteTask   AveDiskWrite    ReqTRES  AllocTRES TRESUsageInAve TRESUsageInMax TRESUsageInMaxNode TRESUsageInMaxTask TRESUsageInMin TRESUsageInMinNode TRESUsageInMinTask TRESUsageInTot TRESUsageOutMax TRESUsageOutMaxNode TRESUsageOutMaxTask TRESUsageOutAve TRESUsageOutTot 
------------ ------------ ---------- ---------- ---------- -------------- -------------- ---------- ---------- ---------- ---------- ---------- -------- ------------ -------------- ---------- ---------- ---------- ---------- ---------- -------- ---------- ---------- ---------- -------- ---------- ------------- ------------- ------------- ---------- -------------- ------------ --------------- --------------- -------------- ------------ ---------------- ---------------- -------------- ---------- ---------- -------------- -------------- ------------------ ------------------ -------------- ------------------ ------------------ -------------- --------------- ------------------- ------------------- --------------- --------------- 
36513389     36513389     scbertpre+    compute                                                                                                                                                                                                              32   00:03:44    RUNNING      0:0                  Unknown       Unknown       Unknown       720G                                                                                                                                          billing=3+ billing=3+                                                                                                                                                                                                                                 
36513389.ba+ 36513389.ba+      batch                                                                                                                                                                                                               1         32   00:03:44    RUNNING      0:0          0             0             0             0                         0                                                                                                                                      cpu=32,gr+                                                                                                                                                                                                                                 
